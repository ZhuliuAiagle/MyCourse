%
%
\documentclass[12pt,twoside]{article}

\input{macros}

\usepackage{amsmath}
\usepackage{url}
\usepackage{mdwlist}
\usepackage{graphicx}
\usepackage{clrscode3e}
\newcommand{\isnotequal}{\mathrel{\scalebox{0.8}[1]{!}\hspace*{1pt}\scalebox{0.8}[1]{=}}}
\usepackage{listings}
\usepackage{tikz}
\usepackage{float}
\usetikzlibrary{arrows}
\usetikzlibrary{matrix}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{shapes.misc}
\usetikzlibrary{trees}

\usepackage{hyperref}
\usepackage[all]{hypcap}
\usepackage{caption}
\usepackage{subfigure}
\captionsetup{hypcap=true}

\newcommand{\answer}{
 \par\medskip
 \textbf{Answer:}
}

\newcommand{\collaborators}{ \textbf{Collaborators:}
%%% COLLABORATORS START %%%

\tabT Name: Shen Zijin

\tabT Student ID: 3160104734
%%% COLLABORATORS END %%%
}

\newcommand{\answerIa}{ \answer
%%% PROBLEM 1(a) ANSWER START %%%
After training by such a 3-layer neural network,
According to the output result in the console, the loss reaches about $0.236$, and the accuracy reaches about $93.5\%$.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{assets/1.png}
	\caption{The result shown in the console}
	\label{figure1}
\end{figure}
%%% PROBLEM 1(a) ANSWER END %%%
}

\newcommand{\answerIIa}{ \answer
%%% PROBLEM 2(a) ANSWER START %%%
Assume that $K = [1, 10 ,100]$. The output figure are shown below:
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.8]{assets/2-1.eps}
	\caption{Figure when $K = 1$}
	\label{figure2}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.8]{assets/2-2.eps}
	\caption{Figure when $K = 10$}
	\label{figure3}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.8]{assets/2-3.eps}
	\caption{Figure when $K = 100$}
	\label{figure4}
\end{figure}
%%% PROBLEM 2(a) ANSWER END %%%
}


\newcommand{\answerIIb}{ \answer
%%% PROBLEM 2(b) ANSWER START %%%
$K$ ought to based on the No. of classed as well as train data. Assume that the No. of 
train data is $Count(train)$, and the No. of classed is $Count(class)$, then:$K \leq \left\lfloor\frac{Count(train)}{Count(class)} \right\rfloor$.
The smaller the difference between $K$ and the right-hand-side expression, 
the more linear the decision boundry is.

%%% PROBLEM 2(b) ANSWER END %%%
}

\newcommand{\answerIIc}{ \answer
	%%% PROBLEM 2(c) ANSWER START %%%
	I used the python crawler to crawl 20 training sets and manually filter and mark each training set.
	Then I wrote a python script $fetch\_code.py$ that was designed to crawl or update the test set. The test set is updated each time the script is executed. Since the verification codes 
	of the target websites are not always different, I set the test set size to 10, and I will select five of them to display.
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.6]{assets/2-4.eps}
		\label{figure5}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.6]{assets/2-5.eps}
		
		\label{figure6}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.6]{assets/2-6.eps}
		\label{figure7}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.6]{assets/2-7.eps}
		\label{figure8}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.6]{assets/2-8.eps}
		\label{figure9}
	\end{figure}
	%%% PROBLEM 2(c) ANSWER END %%%
}



\newcommand{\answerIIIa}{ \answer 
%%% PROBLEM 3(a) ANSWER START %%%
$$
\begin{aligned}
& Entropy(S) = - \sum_{i=1}^c{P_i\log{P_i}} =  0.991
\\& Gain(S, GPA) = 0.4266
\\& Gain(S, Gender) = 0.0112
\end{aligned}
$$



\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{assets/3.png}
	\caption{Decision Tree}
	\label{figure10}
\end{figure}
%%% PROBLEM 3(a) ANSWER END %%%

}

\newcommand{\answerIIIIa}{ \answer
	%%% PROBLEM 4(a) ANSWER START %%%
	
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.8]{assets/4-1.eps}
		\caption{Two trails with the largest and the smallest SD.}
		\label{figure11}
	\end{figure}
	%%% PROBLEM 4(a) ANSWER END %%%
}

\newcommand{\answerIIIIb}{ \answer
	%%% PROBLEM 4(b) ANSWER START %%%
	It will be better to run k-means for serval times and 
	get average or maximum.
	%%% PROBLEM 4(b) ANSWER END %%%
}

\newcommand{\answerIIIIc}{ \answer
	%%% PROBLEM 4(c) ANSWER START %%%
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.7]{assets/4-2.eps}
		\caption{$K=10$}
		\label{figure12}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.7]{assets/4-3.eps}
		\caption{$K=20$}
		\label{figure13}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.7]{assets/4-4.eps}
		\caption{$K=50$}
		\label{figure14}
	\end{figure}
	%%% PROBLEM 4(c) ANSWER END %%%
}

\newcommand{\answerIIIId}{ \answer
	%%% PROBLEM 4(d) ANSWER START %%%
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.32]{assets/4-9.jpg}
		\caption{Original image}
		\label{figure15}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.32]{assets/4-5.jpg}
		\caption{$K=8$}
		\label{figure16}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.32]{assets/4-6.jpg}
		\caption{$K=16$}
		\label{figure17}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.32]{assets/4-7.jpg}
		\caption{$K=32$}
		\label{figure18}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.32]{assets/4-8.jpg}
		\caption{$K=64$}
		\label{figure19}
	\end{figure}
	If we use RGB, then the size of original image is $Np*24$, where $Np$ is the number of pixels in the original images;
	If we use kmeans, the size of the image is $Np*log_2K$;
	So the compression ratio is $\frac{Np*log_2K}{24Np} = \frac{log_2K}{24} = 25\%$
	%%% PROBLEM 4(d) ANSWER END %%%
}

\setlength{\oddsidemargin}{0pt}
\setlength{\evensidemargin}{0pt}
\setlength{\textwidth}{6.5in}
\setlength{\topmargin}{0in}
\setlength{\textheight}{8.5in}

% Fill these in!
\newcommand{\theproblemsetnum}{3}
\newcommand{\releasedate}{May 27, 2019}
\newcommand{\partaduedate}{Thursday, June 13}
\newcommand{\tabUnit}{3ex}
\newcommand{\tabT}{\hspace*{\tabUnit}}

\begin{document}

\handout{Homework \theproblemsetnum}{\releasedate}

%\textbf{Both theory and programming questions} are due {\bf \partaduedate} at
%{\bf 11:59PM}.
%
\collaborators
%Please download the .zip archive for this problem set.
% Your grade will be based on both your solutions and the grading explanation.

\medskip

\hrulefill

\begin{problems}

\problem \textbf{Neural Networks}

In this problem, we will implement the feedforward and backpropagation process of
the neural networks.
\begin{problemparts}
\problempart 
\answerIa

\end{problemparts}

\problem \textbf{K-Nearest Neighbor}

In this problem, we will play with K-Nearest Neighbor (KNN) algorithm and try it on
real-world data. Implement KNN algorithm (in \emph{knn.m}/\emph{knn.py}), then answer the following questions.
\begin{problemparts}
\problempart
Try KNN with different K and plot the decision boundary.


\answerIIa

\problempart We have seen the effects of different choices of K. How can you choose a proper K
when dealing with real-world data ?

\answerIIb

\problempart Finish \emph{hack.m}/\emph{hack.py} to recognize the CAPTCHA image using KNN algorithm.

\answerIIc
\end{problemparts}

\problem \textbf{Decision Tree and ID3}

Consider the scholarship evaluation problem: selecting scholarship recipients based on gender
and GPA. Given the following training data:

\answerIIIa


\problem \textbf{K-Means Clustering}

Finally, we will run our first unsupervised algorithm â€“ k-means clustering.
\begin{problemparts}
	\problempart
	Visualize the process of k-means algorithm for the two trials.
	
	\answerIIIIa
	
	\problempart How can we get a stable result using k-means?
	
	\answerIIIIb
	
	\problempart  Visualize the centroids.
	
	\answerIIIIc
	
	\problempart  Vector quantization.
	
	\answerIIIId
	
\end{problemparts}


\end{problems}
\end{document}
